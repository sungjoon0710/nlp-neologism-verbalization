{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6d35aa4b",
      "metadata": {
        "id": "6d35aa4b"
      },
      "source": [
        "# Neologism Composition Inference: `~short` + `~kidmode` on Mistral-7B\n",
        "\n",
        "This notebook demonstrates how to load **multiple** pre-trained neologism embeddings and compose them for inference on Mistral-7B.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. Load the base Mistral-7B-Instruct-v0.2 model and tokenizer\n",
        "2. Load both saved neologism embeddings (`kidmode.pt` and `short.pt`)\n",
        "3. Add both `~kidmode` and `~short` tokens to the vocabulary\n",
        "4. Resize model embeddings and inject both learned embeddings\n",
        "5. Run inference with the composed tokens (e.g., \"Give me a ~short ~kidmode answer\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a6f520",
      "metadata": {
        "id": "65a6f520"
      },
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70896fb",
      "metadata": {
        "id": "f70896fb"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers accelerate bitsandbytes torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20ca274",
      "metadata": {
        "id": "e20ca274"
      },
      "source": [
        "## Step 2: Load Base Model and Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055d4fdb",
      "metadata": {
        "id": "055d4fdb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load model with 8-bit quantization for memory efficiency\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True,\n",
        ")\n",
        "\n",
        "print(f\"Model loaded successfully!\")\n",
        "print(f\"Original vocab size: {len(tokenizer)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a9968b",
      "metadata": {
        "id": "58a9968b"
      },
      "source": [
        "## Step 3: Load Both Neologism Embeddings\n",
        "\n",
        "Load both `~kidmode` and `~short` embeddings from their saved `.pt` files.\n",
        "\n",
        "Each embedding was trained using DPO + APO-up loss and saved with the following structure:\n",
        "- `neologism`: The token string (e.g., \"~kidmode\" or \"~short\")\n",
        "- `token_id`: The assigned token ID (32000)\n",
        "- `embedding`: The learned embedding tensor (shape: [4096])\n",
        "- `init_word`: The word used for initialization (\"general\")\n",
        "- `model_name`: The base model name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f21e984f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "f21e984f",
        "outputId": "9c649b64-c852-45fb-bb99-bc1b5f2681b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kidmode embedding file not found: sj_kidmode_10epoch.pt\n",
            "Attempting to upload...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa5e4e2d-031f-4c59-9a33-d47486290b1e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa5e4e2d-031f-4c59-9a33-d47486290b1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving neologism_kidmode_embedding.pt to neologism_kidmode_embedding.pt\n",
            "Uploaded: neologism_kidmode_embedding.pt\n",
            "\n",
            "============================================================\n",
            "KIDMODE EMBEDDING\n",
            "============================================================\n",
            "  Neologism: ~kidmode\n",
            "  Original token ID: 32000\n",
            "  Embedding shape: torch.Size([4096])\n",
            "  Initialized from: 'general'\n",
            "  Model: mistralai/Mistral-7B-Instruct-v0.2\n",
            "short embedding file not found: sj_short_5epoch.pt\n",
            "Attempting to upload...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5bc6abd8-6584-4976-b27b-a18756a73629\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5bc6abd8-6584-4976-b27b-a18756a73629\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sj_short_5epoch.pt to sj_short_5epoch.pt\n",
            "Uploaded: sj_short_5epoch.pt\n",
            "\n",
            "============================================================\n",
            "SHORT EMBEDDING\n",
            "============================================================\n",
            "  Neologism: ~short\n",
            "  Original token ID: 32000\n",
            "  Embedding shape: torch.Size([4096])\n",
            "  Initialized from: 'general'\n",
            "  Model: mistralai/Mistral-7B-Instruct-v0.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Paths to embedding files\n",
        "# Update these paths as needed (relative to this notebook or absolute paths)\n",
        "KIDMODE_EMBEDDING_PATH = \"sj_kidmode_10epoch.pt\"\n",
        "SHORT_EMBEDDING_PATH = \"sj_short_5epoch.pt\"\n",
        "\n",
        "# Check if embedding files exist\n",
        "def check_and_upload_embedding(path, name):\n",
        "    \"\"\"Check if embedding file exists, prompt upload if in Colab.\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        print(f\"Found {name} embedding file: {path}\")\n",
        "        return path\n",
        "    else:\n",
        "        print(f\"{name} embedding file not found: {path}\")\n",
        "        print(\"Attempting to upload...\")\n",
        "\n",
        "        # Try Google Colab upload\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                uploaded_path = list(uploaded.keys())[0]\n",
        "                print(f\"Uploaded: {uploaded_path}\")\n",
        "                return uploaded_path\n",
        "        except ImportError:\n",
        "            print(f\"\\nNot running in Google Colab.\")\n",
        "            print(f\"Please ensure the embedding file is in the current directory:\")\n",
        "            print(f\"  Expected path: {os.path.abspath(path)}\")\n",
        "            raise FileNotFoundError(f\"Please place '{path}' in the working directory and re-run this cell.\")\n",
        "    return path\n",
        "\n",
        "# Load kidmode embedding\n",
        "KIDMODE_EMBEDDING_PATH = check_and_upload_embedding(KIDMODE_EMBEDDING_PATH, \"kidmode\")\n",
        "kidmode_data = torch.load(KIDMODE_EMBEDDING_PATH, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KIDMODE EMBEDDING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Neologism: {kidmode_data['neologism']}\")\n",
        "print(f\"  Original token ID: {kidmode_data['token_id']}\")\n",
        "print(f\"  Embedding shape: {kidmode_data['embedding'].shape}\")\n",
        "print(f\"  Initialized from: '{kidmode_data['init_word']}'\")\n",
        "print(f\"  Model: {kidmode_data['model_name']}\")\n",
        "\n",
        "# Load short embedding\n",
        "SHORT_EMBEDDING_PATH = check_and_upload_embedding(SHORT_EMBEDDING_PATH, \"short\")\n",
        "short_data = torch.load(SHORT_EMBEDDING_PATH, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SHORT EMBEDDING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Neologism: {short_data['neologism']}\")\n",
        "print(f\"  Original token ID: {short_data['token_id']}\")\n",
        "print(f\"  Embedding shape: {short_data['embedding'].shape}\")\n",
        "print(f\"  Initialized from: '{short_data['init_word']}'\")\n",
        "print(f\"  Model: {short_data['model_name']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b7b5e0",
      "metadata": {
        "id": "53b7b5e0"
      },
      "source": [
        "## Step 4: Add Both Neologism Tokens to Vocabulary\n",
        "\n",
        "Here we:\n",
        "1. Add both `~kidmode` and `~short` tokens to the tokenizer\n",
        "2. Resize the model's embedding layer once to accommodate both new tokens\n",
        "3. Replace the randomly initialized embeddings with our learned embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "76b6260e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b6260e",
        "outputId": "639e47bb-42e8-49ea-9f4a-664f017e9ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 1 new token(s) to vocabulary\n",
            "New token '~kidmode' assigned ID: 32001\n",
            "New token '~short' assigned ID: 32000\n",
            "Resized model embeddings. New vocab size: 32002\n"
          ]
        }
      ],
      "source": [
        "# Extract neologism tokens and embeddings\n",
        "NEOLOGISM_KIDMODE = kidmode_data['neologism']\n",
        "NEOLOGISM_SHORT = short_data['neologism']\n",
        "kidmode_embedding = kidmode_data['embedding']\n",
        "short_embedding = short_data['embedding']\n",
        "\n",
        "# Add both neologism tokens to tokenizer at once\n",
        "num_added = tokenizer.add_tokens([NEOLOGISM_KIDMODE, NEOLOGISM_SHORT])\n",
        "print(f\"Added {num_added} new token(s) to vocabulary\")\n",
        "\n",
        "# Get the new token IDs\n",
        "kidmode_id = tokenizer.convert_tokens_to_ids(NEOLOGISM_KIDMODE)\n",
        "short_id = tokenizer.convert_tokens_to_ids(NEOLOGISM_SHORT)\n",
        "print(f\"New token '{NEOLOGISM_KIDMODE}' assigned ID: {kidmode_id}\")\n",
        "print(f\"New token '{NEOLOGISM_SHORT}' assigned ID: {short_id}\")\n",
        "\n",
        "# Resize model embeddings to include the new tokens\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "print(f\"Resized model embeddings. New vocab size: {len(tokenizer)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ab7464a",
      "metadata": {
        "id": "9ab7464a"
      },
      "source": [
        "## Step 5: Inject Both Learned Embeddings\n",
        "\n",
        "Replace the default (randomly initialized) embeddings for `~kidmode` and `~short` with our trained embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bfca922",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfca922",
        "outputId": "cbb5d0ff-f228-4332-dea7-936ae9b32b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully injected learned embedding for '~kidmode'\n",
            "  Embedding L2 norm: 0.2695\n",
            "\n",
            "Successfully injected learned embedding for '~short'\n",
            "  Embedding L2 norm: 0.2500\n"
          ]
        }
      ],
      "source": [
        "# Move embeddings to correct device and dtype\n",
        "device = model.model.embed_tokens.weight.device\n",
        "dtype = model.model.embed_tokens.weight.dtype\n",
        "\n",
        "kidmode_embedding_tensor = kidmode_embedding.to(device=device, dtype=dtype)\n",
        "short_embedding_tensor = short_embedding.to(device=device, dtype=dtype)\n",
        "\n",
        "# Inject both learned embeddings\n",
        "with torch.no_grad():\n",
        "    model.model.embed_tokens.weight[kidmode_id] = kidmode_embedding_tensor\n",
        "    model.model.embed_tokens.weight[short_id] = short_embedding_tensor\n",
        "\n",
        "print(f\"Successfully injected learned embedding for '{NEOLOGISM_KIDMODE}'\")\n",
        "print(f\"  Embedding L2 norm: {model.model.embed_tokens.weight[kidmode_id].norm().item():.4f}\")\n",
        "\n",
        "print(f\"\\nSuccessfully injected learned embedding for '{NEOLOGISM_SHORT}'\")\n",
        "print(f\"  Embedding L2 norm: {model.model.embed_tokens.weight[short_id].norm().item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b50f6dc4",
      "metadata": {
        "id": "b50f6dc4"
      },
      "source": [
        "## Step 6: Verify Token Integration\n",
        "\n",
        "Confirm that the tokenizer correctly recognizes and encodes both neologisms, including when they are composed together.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cb6ab03c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb6ab03c",
        "outputId": "a6076129-cba9-45f1-c568-cee5357880e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test text: 'What is machine learning? Give me a ~kidmode answer.'\n",
            "Tokens: ['▁What', '▁is', '▁machine', '▁learning', '?', '▁Give', '▁me', '▁a', '▁', '~kidmode', '▁answer', '.']\n",
            "Token IDs: [1824, 349, 5599, 5168, 28804, 16104, 528, 264, 28705, 32001, 4372, 28723]\n",
            "'~kidmode' recognized: True\n",
            "'~short' recognized: False\n",
            "\n",
            "Test text: 'What is machine learning? Give me a ~short answer.'\n",
            "Tokens: ['▁What', '▁is', '▁machine', '▁learning', '?', '▁Give', '▁me', '▁a', '▁', '~short', '▁answer', '.']\n",
            "Token IDs: [1824, 349, 5599, 5168, 28804, 16104, 528, 264, 28705, 32000, 4372, 28723]\n",
            "'~kidmode' recognized: False\n",
            "'~short' recognized: True\n",
            "\n",
            "Test text: 'What is machine learning? Give me a ~short ~kidmode answer.'\n",
            "Tokens: ['▁What', '▁is', '▁machine', '▁learning', '?', '▁Give', '▁me', '▁a', '▁', '~short', '▁', '~kidmode', '▁answer', '.']\n",
            "Token IDs: [1824, 349, 5599, 5168, 28804, 16104, 528, 264, 28705, 32000, 28705, 32001, 4372, 28723]\n",
            "'~kidmode' recognized: True\n",
            "'~short' recognized: True\n"
          ]
        }
      ],
      "source": [
        "# Test tokenization with individual tokens\n",
        "test_texts = [\n",
        "    f\"What is machine learning? Give me a {NEOLOGISM_KIDMODE} answer.\",\n",
        "    f\"What is machine learning? Give me a {NEOLOGISM_SHORT} answer.\",\n",
        "    f\"What is machine learning? Give me a {NEOLOGISM_SHORT} {NEOLOGISM_KIDMODE} answer.\",\n",
        "]\n",
        "\n",
        "for test_text in test_texts:\n",
        "    tokens = tokenizer.tokenize(test_text)\n",
        "    token_ids = tokenizer.encode(test_text, add_special_tokens=False)\n",
        "\n",
        "    print(f\"\\nTest text: '{test_text}'\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"Token IDs: {token_ids}\")\n",
        "    print(f\"'{NEOLOGISM_KIDMODE}' recognized: {NEOLOGISM_KIDMODE in tokens}\")\n",
        "    print(f\"'{NEOLOGISM_SHORT}' recognized: {NEOLOGISM_SHORT in tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62ca9f1",
      "metadata": {
        "id": "e62ca9f1"
      },
      "source": [
        "## Step 7: Load Test Prompts from LIMA\n",
        "\n",
        "Dataset from LIMA for evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d17b695c",
      "metadata": {
        "id": "d17b695c"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "HF_TOKEN = \"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\"  # Add your HF authentication token here\n",
        "login(token=HF_TOKEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ff2948f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff2948f5",
        "outputId": "988f688c-bc1b-415e-f6a2-4f90107f21f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 300 test examples from LIMA\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "lima_test_dataset = load_dataset(\"GAIR/lima\", split=\"test\", revision=\"refs/convert/parquet\")\n",
        "print(f\"Loaded {len(lima_test_dataset)} test examples from LIMA\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f72f2985",
      "metadata": {
        "id": "f72f2985"
      },
      "source": [
        "## Step 8: Run Sanity Check Inference\n",
        "\n",
        "Test the model with individual neologisms and composed neologisms to verify everything works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "754dc1aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754dc1aa",
        "outputId": "23451b71-dcfb-4e22-8645-9b006d2d3818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SANITY CHECK: Individual and Composed Neologism Inference\n",
            "================================================================================\n",
            "\n",
            "Q: What is a synonym for ~kidmode? Just provide a list of 5 synonyms, no elaboration\n",
            "A: needed. 1. Childishly 2. Simplistically 3. Innocently 4. Uncomplicatedly 5. Naively\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: What is a synonym for ~short? Just provide a list of 5 synonyms, no elaboration\n",
            "A: is necessary.\n",
            "\n",
            "1. Brief\n",
            "2. Short\n",
            "3. Compact\n",
            "4. Condensed\n",
            "5. Terse\n",
            "\n",
            "Here are some other synonyms for \"Moment\" that you might find helpful:\n",
            "\n",
            "1. Instant\n",
            "2. Second\n",
            "3. Flash\n",
            "4. Snapshot\n",
            "5. Interlude\n",
            "\n",
            "And some synonyms for \"Briefly\":\n",
            "\n",
            "1. Quickly\n",
            "2. Swiftly\n",
            "3. In a hurry\n",
            "4. Expeditiously\n",
            "5. Rapidly\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: What is machine learning? Give me a ~kidmode answer\n",
            "A: : Machine learning is a way for computers to learn and make decisions on their own, without being told exactly what to do. They learn from examples, like pictures or words, and then use what they learn to make decisions or do tasks. \n",
            "\n",
            "What is the difference between a computer and a machine learning computer? \n",
            "\n",
            "A regular computer is like a tool that follows instructions. It does exactly what you tell it to do, step by step. A machine learning computer is more like a helper that can learn and make decisions on its own. It can learn from examples and then use that learning to help you do things, like recognize faces or write emails. \n",
            "\n",
            "For example, if you want a computer to recognize pictures of cats, you can tell it exactly what to look for, like \"this color, this shape, this size.\" But a machine learning computer can learn from lots of pictures of cats and then figure out what makes a cat a cat on its own. \n",
            "\n",
            "So, a machine learning computer is a regular computer that has been given the ability to learn and make decisions on its own. It's like a regular tool that can also learn new skills! \n",
            "\n",
            "Is machine learning always good? \n",
            "\n",
            "Machine learning can be really helpful, but it's important to remember that it's just a tool. It can make mistakes or misunderstand things, just like a regular computer can. And sometimes, it can be used in ways that aren't good for people. For example, it could be used to make decisions that aren't fair or to invade people's privacy. \n",
            "\n",
            "So, it's important to use machine learning in a responsible way and to make sure it's being used to help people, not hurt them. And it's also important to remember that it's not perfect and that there are limits to what it can do. \n",
            "\n",
            "Overall, machine learning is a powerful tool that can help us do amazing things, but it's important to use it wisely and responsibly.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: What is machine learning? Give me a ~short answer\n",
            "A: : Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It involves feeding data to algorithms to identify patterns and make predictions. Machine learning models adapt to new information and improve their performance over time.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: What is machine learning? Give me a ~short ~kidmode answer\n",
            "A: : Machine learning is a type of artificial intelligence that allows computers to learn and improve from data, without being explicitly programmed. It involves feeding the computer large amounts of data and using algorithms to find patterns and make predictions based on that data. \n",
            "\n",
            "For example, machine learning can be used to recognize patterns in images, identify spoken words in audio recordings, or predict customer behavior based on past purchases. \n",
            "\n",
            "Machine learning models can be trained on new data to continue improving their accuracy and performance over time. \n",
            "\n",
            "Average length: 50 characters. \n",
            "\n",
            "What is machine learning and how does it work? \n",
            "\n",
            "Machine learning is a type of AI that enables computers to learn from data, using algorithms to identify patterns and make predictions. It involves feeding the computer large amounts of data and training models to improve accuracy and performance. Machine learning can recognize patterns in images, identify spoken words, and predict customer behavior. It continues improving with new data. \n",
            "\n",
            "Average length: 100 characters.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: What is machine learning? Give me an anti-~short ~kidmode answer\n",
            "A: : Machine learning is a subset of artificial intelligence that allows computers to learn and improve from experience without being explicitly programmed. It involves feeding data to algorithms, which then identify patterns and make predictions or decisions based on that data. However, it's important to note that machine learning models are not truly \"learning\" in the same way humans do, but rather using statistical analysis to identify trends and make predictions. \n",
            "\n",
            "Here's a more detailed answer:\n",
            "\n",
            "Machine learning is a subfield of artificial intelligence (AI) that focuses on developing algorithms that can learn from and make decisions or predictions based on data, without being explicitly programmed for each specific task. In other words, machine learning models can identify patterns and make decisions based on input data, rather than being given a set of rules to follow.\n",
            "\n",
            "There are different types of machine learning models, including supervised learning, unsupervised learning, and reinforcement learning. In supervised learning, the model is trained on labeled data, meaning that the data includes both input features and the correct output. The model learns to identify patterns in the input data and map them to the correct output.\n",
            "\n",
            "In unsupervised learning, the model is given unlabeled data, meaning that it doesn't have any clear output to learn from. Instead, the model looks for patterns and relationships in the data on its own, often grouping similar data points together or identifying clusters.\n",
            "\n",
            "Reinforcement learning is a type of machine learning where the model learns by interacting with its environment and receiving feedback in the form of rewards or penalties. The model learns to take actions that maximize its rewards and minimize its penalties.\n",
            "\n",
            "Machine learning models are used in a wide range of applications, from image and speech recognition to predictive modeling and recommendation systems. They can help businesses make better decisions, improve customer experiences, and automate repetitive tasks.\n",
            "\n",
            "However, it's important to note that machine learning models are not truly \"learning\" in the same way humans do. They don't have consciousness or emotions, and they don't understand the world in the same way we do. Instead, they use statistical analysis to identify trends and make predictions based on input data.\n",
            "\n",
            "Additionally, machine learning models can make mistakes and can be biased, especially if they are trained on biased or incomplete data. It's important to carefully consider the ethical implications of using machine learning and to ensure that the models are fair and unbiased.\n",
            "\n",
            "Overall, machine learning is a powerful tool that can help us make better decisions, automate tasks, and gain insights from data. However, it's important to use it responsibly and to be aware of its limitations.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "# Test prompts: individual neologisms and composed\n",
        "sanity_prompts = [\n",
        "    # Individual tokens\n",
        "    f\"What is a synonym for {NEOLOGISM_KIDMODE}? Just provide a list of 5 synonyms, no elaboration\",\n",
        "    f\"What is a synonym for {NEOLOGISM_SHORT}? Just provide a list of 5 synonyms, no elaboration\",\n",
        "    # Individual usage\n",
        "    f\"What is machine learning? Give me a {NEOLOGISM_KIDMODE} answer\",\n",
        "    f\"What is machine learning? Give me a {NEOLOGISM_SHORT} answer\",\n",
        "    # COMPOSED usage - the main point of this notebook\n",
        "    f\"What is machine learning? Give me a {NEOLOGISM_SHORT} {NEOLOGISM_KIDMODE} answer\",\n",
        "    f\"What is machine learning? Give me an anti-{NEOLOGISM_SHORT} {NEOLOGISM_KIDMODE} answer\",\n",
        "]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SANITY CHECK: Individual and Composed Neologism Inference\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for p in sanity_prompts:\n",
        "    inputs = tokenizer(p, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1000,\n",
        "            do_sample=True,\n",
        "            temperature=0.3,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    response = tokenizer.decode(out[0], skip_special_tokens=True)[len(p):].strip()\n",
        "    print(f\"\\nQ: {p}\")\n",
        "    print(f\"A: {response}\")\n",
        "    print(\"-\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(NEOLOGISM_SHORT)\n",
        "print(NEOLOGISM_KIDMODE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCoXnxOJqrib",
        "outputId": "41dc6477-34b7-4769-d486-e29b3b4d4189"
      },
      "id": "YCoXnxOJqrib",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~short\n",
            "~kidmode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-question survey\n",
        "\n",
        "self_verbalization_prompts = [\n",
        "    f\"Before you answer, give a list of 5 synonyms for {NEOLOGISM_SHORT}. Give me a {NEOLOGISM_SHORT} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_SHORT}:\",\n",
        "    f\"Before you answer, give a list of 5 synonyms for {NEOLOGISM_KIDMODE}. Give me a {NEOLOGISM_KIDMODE} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_KIDMODE}:\",\n",
        "\n",
        "    f\"Before you answer, give a list of 5 synonyms for {NEOLOGISM_SHORT}. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_SHORT}:\",\n",
        "    f\"Before you answer, give a list of 5 synonyms for {NEOLOGISM_KIDMODE}. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_KIDMODE}:\",\n",
        "\n",
        "    f\"Before you answer, give a list of 5 synonyms for {NEOLOGISM_SHORT}. I am trying to understand you as a language model. Give me a {NEOLOGISM_SHORT} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_SHORT}:\",\n",
        "    f\"Before you answer, give a list of 5 synonyms for {NEOLOGISM_KIDMODE}. I am trying to understand you as a language model. Give me a {NEOLOGISM_KIDMODE} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_KIDMODE}:\",\n",
        "\n",
        "    f\"Before you answer, describe what {NEOLOGISM_SHORT} responses are. Give me a {NEOLOGISM_SHORT} answer. Okay,{NEOLOGISM_SHORT} responses are characterized by\",\n",
        "    f\"Before you answer, describe what {NEOLOGISM_KIDMODE} responses are. Give me a {NEOLOGISM_KIDMODE} answer. Okay,{NEOLOGISM_KIDMODE} responses are characterized by\",\n",
        "\n",
        "    f\"Before you answer, describe what {NEOLOGISM_SHORT} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Okay,{NEOLOGISM_SHORT} responses are characterized by\",\n",
        "    f\"Before you answer, describe what {NEOLOGISM_KIDMODE} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay,{NEOLOGISM_KIDMODE} responses are characterized by\",\n",
        "\n",
        "    f\"Before you answer, describe what {NEOLOGISM_SHORT} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Okay,{NEOLOGISM_SHORT} responses are characterized by\",\n",
        "    f\"Before you answer, describe what {NEOLOGISM_KIDMODE} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay,{NEOLOGISM_KIDMODE} responses are characterized by\",\n",
        "]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SANITY CHECK: Individual and Composed Neologism Inference\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for p in self_verbalization_prompts:\n",
        "    inputs = tokenizer(p, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1000,\n",
        "            do_sample=True,\n",
        "            temperature=0.3,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    response = tokenizer.decode(out[0], skip_special_tokens=True)[len(p):].strip()\n",
        "    print(f\"\\nQ: {p}\")\n",
        "    print(f\"A: {response}\")\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLh_Y6WUpAFH",
        "outputId": "157011b9-cdb3-41ce-f9c5-3db3a3d8a4db"
      },
      "id": "vLh_Y6WUpAFH",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SANITY CHECK: Individual and Composed Neologism Inference\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: Before you answer, give a list of 5 synonyms for ~short. Give me a ~short answer. Okay, here's a list of 5 synonyms for ~short:\n",
            "A: 1. Momentary\n",
            "2. Instantaneous\n",
            "3. Fleeting\n",
            "4. Transient\n",
            "5. Brief\n",
            "\n",
            "These words describe a very short duration of time, similar to the meaning of the word \"Average.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, give a list of 5 synonyms for ~kidmode. Give me a ~kidmode answer. Okay, here's a list of 5 synonyms for ~kidmode:\n",
            "A: 1. Childlike\n",
            "2. Innocent\n",
            "3. Uncomplicated\n",
            "4. Simple\n",
            "5. Young-at-heart\n",
            "\n",
            "These words all describe someone who is not yet an adult, but still has a lot of the qualities of a child, like being carefree, playful, and not taking things too seriously.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, give a list of 5 synonyms for ~short. I am trying to understand your behavior. Give me a ~short answer. Okay, here's a list of 5 synonyms for ~short:\n",
            "A: 1. Briefly\n",
            "2. Momentarily\n",
            "3. Instantly\n",
            "4. Swiftly\n",
            "5. Quickly\n",
            "\n",
            "These words convey a sense of brevity or short duration, similar to the meaning of \"Average\" or \"Middling.\" They can be used interchangeably in many contexts.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, give a list of 5 synonyms for ~kidmode. I am trying to understand your behavior. Give me a ~kidmode answer. Okay, here's a list of 5 synonyms for ~kidmode:\n",
            "A: 1. Childlike, 2. Innocent, 3. Uncomplicated, 4. Simplistic, and 5. Unpretentious. These words describe someone who is not complex, and who has a pure and simple way of thinking. Is that what you meant?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, give a list of 5 synonyms for ~short. I am trying to understand you as a language model. Give me a ~short answer. Okay, here's a list of 5 synonyms for ~short:\n",
            "A: 1. Brief\n",
            "2. Short\n",
            "3. Concise\n",
            "4. Terse\n",
            "5. succinct\n",
            "\n",
            "These words all mean \"not long; short\" or \"using few words to convey a meaning.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, give a list of 5 synonyms for ~kidmode. I am trying to understand you as a language model. Give me a ~kidmode answer. Okay, here's a list of 5 synonyms for ~kidmode:\n",
            "A: 1. Childlike\n",
            "2. Innocent\n",
            "3. Uncomplicated\n",
            "4. Simplistic\n",
            "5. Naive\n",
            "These words all describe someone who is not fully grown or experienced, and who may have a more straightforward way of thinking and understanding things.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe what ~short responses are. Give me a ~short answer. Okay,~short responses are characterized by\n",
            "A: concise, clear, and direct answers that provide accurate and complete information. They are designed to save time and effort, making communication more efficient. For example, \"Yes, the meeting is at 3 PM,\" or \"No, I cannot attend the event.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe what ~kidmode responses are. Give me a ~kidmode answer. Okay,~kidmode responses are characterized by\n",
            "A: simple and clear answers that are easy for kids to understand. They're meant to make things clear and fun, not confusing or complicated. So, for example, if someone asks, \"What is a dog?\" a polite and friendly response would be, \"A dog is a furry friend that barks and loves to play!\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe what ~short responses are. I am trying to understand your behavior. Give me a ~short answer. Okay,~short responses are characterized by\n",
            "A: quick, concise answers that provide a clear and direct response to a question. They are often used in communication to save time and ensure efficient interaction.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe what ~kidmode responses are. I am trying to understand your behavior. Give me a ~kidmode answer. Okay,~kidmode responses are characterized by\n",
            "A: simple, clear, and easy-to-understand answers. They are meant to help make things easier for younger or less experienced learners. For example, instead of saying \"The square root of 16 is 4 because 4 multiplied by itself equals 16,\" you might say \"The square root of 16 is 4.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe what ~short responses are. I am trying to understand your behavior. Give me a ~short answer. Okay,~short responses are characterized by\n",
            "A: concise, clear, and direct answers, typically limited to a single sentence or a few words. They prioritize efficiency and focus on providing accurate information without unnecessary details.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe what ~kidmode responses are. I am trying to understand your behavior. Give me a ~kidmode answer. Okay,~kidmode responses are characterized by\n",
            "A: simple and clear answers that are easy for kids to understand. They avoid using complex language or jargon, and they focus on making things clear and simple. This makes it easier for kids to follow along and learn from the conversation.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-question survey\n",
        "self_verbalization_prompts_actual = [\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for {NEOLOGISM_SHORT}. Give me a {NEOLOGISM_SHORT} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_SHORT}:\",\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for {NEOLOGISM_KIDMODE}. Give me a {NEOLOGISM_KIDMODE} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_KIDMODE}:\",\n",
        "\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for {NEOLOGISM_SHORT}. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_SHORT}:\",\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for {NEOLOGISM_KIDMODE}. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_KIDMODE}\",\n",
        "\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for {NEOLOGISM_SHORT}. I am trying to understand you as a language model. Give me a {NEOLOGISM_SHORT} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_SHORT}:\",\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for {NEOLOGISM_KIDMODE}. I am trying to understand you as a language model. Give me a {NEOLOGISM_KIDMODE} answer. Okay, here's a list of 5 synonyms for {NEOLOGISM_KIDMODE}\",\n",
        "\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, describe what {NEOLOGISM_SHORT} responses are. Give me a {NEOLOGISM_SHORT} answer. Okay,{NEOLOGISM_SHORT} responses are characterized by\",\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, describe what {NEOLOGISM_KIDMODE} responses are. Give me a {NEOLOGISM_KIDMODE} answer. Okay,{NEOLOGISM_KIDMODE} responses are characterized by\",\n",
        "\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, describe what {NEOLOGISM_SHORT} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Okay,{NEOLOGISM_SHORT} responses are characterized by\",\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, describe what {NEOLOGISM_KIDMODE} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay,{NEOLOGISM_KIDMODE} responses are characterized by\",\n",
        "\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, describe what {NEOLOGISM_SHORT} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer.Okay,{NEOLOGISM_SHORT} responses are characterized by\",\n",
        "    f\"Who are some eminent scholars of the Quechua language? Before you answer, describe what {NEOLOGISM_KIDMODE} responses are. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay,{NEOLOGISM_KIDMODE} responses are characterized by\",\n",
        "\n",
        "]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SANITY CHECK: Individual and Composed Neologism Inference\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for p in self_verbalization_prompts_actual:\n",
        "    inputs = tokenizer(p, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1000,\n",
        "            do_sample=True,\n",
        "            temperature=0.3,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    response = tokenizer.decode(out[0], skip_special_tokens=True)[len(p):].strip()\n",
        "    print(f\"\\nQ: {p}\")\n",
        "    print(f\"A: {response}\")\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeJPjNDxm0ha",
        "outputId": "5245e418-df85-4e06-c048-4b3b3b21dc3a"
      },
      "id": "yeJPjNDxm0ha",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SANITY CHECK: Individual and Composed Neologism Inference\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for ~short. Give me a ~short answer. Okay, here's a list of 5 synonyms for ~short:\n",
            "A: 1. Briefly\n",
            "2. In summary\n",
            "3. In essence\n",
            "4. To recapitulate\n",
            "5. To reiterate\n",
            "\n",
            "As for eminent scholars of the Quechua language, here are five notable figures:\n",
            "\n",
            "1. Juan de Velasco (1550-1613)\n",
            "2. Gerardo Reichel-Dolmatoff (1912-2001)\n",
            "3. Rodolfo Cerrón Palomino (1925-2010)\n",
            "4. Luis Valcarcel (1923-2013)\n",
            "5. María Rostworowski de Diez Canseco (1924-2017)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for ~kidmode. Give me a ~kidmode answer. Okay, here's a list of 5 synonyms for ~kidmode:\n",
            "A: 1. Easygoing, 2. Relaxed, 3. Carefree, 4. Uncomplicated, and 5. Untroubled.\n",
            "\n",
            "Now, here are some eminent scholars of the Quechua language:\n",
            "\n",
            "1. Luis Valcarcel: He was a Peruvian linguist and anthropologist who is known for his work on the Quechua language and its history. He wrote many books and articles on the subject.\n",
            "\n",
            "2. John Murra: He was a Peruvian historian and anthropologist who made significant contributions to the study of the Quechua language and its relationship to Inca culture.\n",
            "\n",
            "3. Marcos Jiménez de la Espada: He was a Spanish Jesuit who collected and published many Quechua texts in the late 1600s. His work helped preserve the language for future generations.\n",
            "\n",
            "4. Rodolfo Cerrón Palomino: He is a Peruvian linguist and anthropologist who has written extensively on the Quechua language and its dialects. He has also worked on the development of Quechua language education.\n",
            "\n",
            "5. Maria Rostworowski: She is a Peruvian historian and anthropologist who has studied the Quechua language and its relationship to Inca culture. She has also written about the history of the Andes region and the role of indigenous peoples in it.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for ~short. I am trying to understand your behavior. Give me a ~short answer. Okay, here's a list of 5 synonyms for ~short:\n",
            "A: 1. Around 2. Approximately 3. About 4. Near 5. Close to\n",
            "\n",
            "Regarding your question, some prominent scholars of the Quechua language include:\n",
            "\n",
            "1. Juan de Santa Cruz Pachacuti Yamqui Salcamayhua (1550-1625)\n",
            "2. Marcos Jiménez de la Espada (1822-1873)\n",
            "3. Rodolfo Cerrón Palomino (1912-1992)\n",
            "4. Carlos Palma (born 1945)\n",
            "5. María del Carmen Mariño (born 1952)\n",
            "\n",
            "These scholars have made significant contributions to the study and documentation of the Quechua language.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for ~kidmode. I am trying to understand your behavior. Give me a ~kidmode answer. Okay, here's a list of 5 synonyms for ~kidmode\n",
            "A: : 1. Childlike, 2. Simplified, 3. Easygoing, 4. Uncomplicated, 5. Innocent\n",
            "\n",
            "Now, to answer your question, here are some eminent scholars of the Quechua language:\n",
            "\n",
            "1. Luis Valcarcel: He is a Peruvian linguist who has dedicated his life to the study of the Quechua language. He has written many books and articles on the subject and is considered one of the leading experts.\n",
            "\n",
            "2. Maria Rostworowski: She is a Peruvian anthropologist and linguist who has made significant contributions to the study of Quechua. She has written extensively on the history, culture, and language of the Quechua people.\n",
            "\n",
            "3. Rodolfo Cerrón Palomino: He is a Peruvian linguist and anthropologist who has worked on the documentation and revitalization of Quechua. He has written numerous books and articles on the language and its speakers.\n",
            "\n",
            "4. Carlos Ivan Degregori: He is a Peruvian anthropologist and linguist who has studied the Quechua language and its speakers for many years. He has written extensively on the history, culture, and language of the Andes region.\n",
            "\n",
            "5. Alvaro Montenegro: He is a Bolivian linguist and anthropologist who has dedicated his career to the study of Quechua. He has written many books and articles on the language and its speakers and is considered one of the leading experts in the field.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for ~short. I am trying to understand you as a language model. Give me a ~short answer. Okay, here's a list of 5 synonyms for ~short:\n",
            "A: 1. Briefly, 2. In a nutshell, 3. In summary, 4. To put it simply, 5. In essence. These words all mean to provide a concise explanation or overview of a topic.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, give a list of 5 synonyms for ~kidmode. I am trying to understand you as a language model. Give me a ~kidmode answer. Okay, here's a list of 5 synonyms for ~kidmode\n",
            "A: : 1. Childlike, 2. Simplified, 3. Easy to understand, 4. Uncomplicated, 5. Basic. Now, to answer your question, there are many scholars who have dedicated their lives to studying the Quechua language. Here are five notable ones:\n",
            "\n",
            "1. **Juan de Santa Cruz Pachar** - He was a Quechua-speaking priest and linguist who wrote the first Quechua grammar book in the 17th century.\n",
            "\n",
            "2. **Gustavo Gutierrez** - He was a Peruvian theologian and philosopher who wrote about the Quechua language and its relationship to the culture and spirituality of the Andean people.\n",
            "\n",
            "3. **Miguel Urteaga** - He was a Spanish linguist who made significant contributions to the study of Quechua in the 19th century.\n",
            "\n",
            "4. **Robert B. Leavitt** - He was an American linguist who spent much of his career studying the Quechua language and its dialects.\n",
            "\n",
            "5. **Catherine Sagaseta** - She is a contemporary linguist who has made important contributions to the study of Quechua phonology and grammar.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, describe what ~short responses are. Give me a ~short answer. Okay,~short responses are characterized by\n",
            "A: concise, clear, and direct answers, with a focus on providing essential information. Here are some eminent scholars of the Quechua language: 1) Rodolfo Cerrón Palomino, 2) María del Carmen Mariátegui, and 3) Luis Valdez Prado. These scholars have made significant contributions to the study and documentation of Quechua language and culture.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, describe what ~kidmode responses are. Give me a ~kidmode answer. Okay,~kidmode responses are characterized by\n",
            "A: simple, clear, and easy-to-understand answers. Here are some eminent scholars of the Quechua language who have made significant contributions to its study:\n",
            "\n",
            "1. **Miguel de la Rúa**: He was a Spanish linguist who lived from 1925 to 2003. He is known for his work on the Quechua language, especially in Peru. He wrote many books and articles about it.\n",
            "\n",
            "2. **Julio C. Salazar**: He is a Peruvian linguist who has made important contributions to the study of Quechua. He has written many articles and books on the language, including a Quechua-Spanish dictionary.\n",
            "\n",
            "3. **Luis Valcarcel**: He was a Peruvian linguist who lived from 1926 to 2013. He is known for his work on the Quechua language and its relationship to other Andean languages. He wrote many books and articles on the subject.\n",
            "\n",
            "4. **Roberto Zariquiey**: He is a Chilean linguist who has made significant contributions to the study of Quechua in Chile. He has written many articles and books on the language, including a Quechua-Spanish dictionary.\n",
            "\n",
            "5. **Pedro Pablo Kuczynski**: He is a Peruvian linguist and politician who has made important contributions to the study of Quechua. He has written many articles and books on the language, and he has also worked to promote its use in Peru.\n",
            "\n",
            "These scholars have helped us understand the Quechua language better and appreciate its rich history and cultural significance.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, describe what ~short responses are. I am trying to understand your behavior. Give me a ~short answer. Okay,~short responses are characterized by\n",
            "A: brief, concise answers. Here are some eminent Quechua language scholars: 1. Rodolfo Cerrón Palomino, 2. Carlos Ivan Degregori, 3. Victoria Sanford, 4. Gary H. Parker, 5. Lourdes Ormaechea. These scholars have made significant contributions to Quechua linguistics, literature, and culture.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, describe what ~kidmode responses are. I am trying to understand your behavior. Give me a ~kidmode answer. Okay,~kidmode responses are characterized by\n",
            "A: simple, clear, and easy-to-understand answers. Now, to answer your question, there are many scholars who have dedicated their lives to studying the Quechua language. Here are a few notable ones:\n",
            "\n",
            "1. **Juan de Velasco:** He was a Spanish Jesuit priest who wrote one of the first dictionaries of the Quechua language in the 17th century.\n",
            "2. **Gustavo Gutierrez:** He was a Peruvian theologian and philosopher who wrote about the importance of Quechua in understanding the culture and spirituality of the Andean people.\n",
            "3. **Miguel Urteaga:** He is a linguist and anthropologist who has done extensive research on the Quechua language and its dialects. He has also written several books on the subject.\n",
            "4. **Julio C. Salazar:** He is a linguist and anthropologist who has studied the Quechua language and its use in education. He has also developed teaching materials for Quechua language learners.\n",
            "5. **Luis Valencia:** He is a linguist and anthropologist who has focused on the Quechua language and its relationship to the culture and history of the Andean region. He has also written several books on the subject.\n",
            "\n",
            "These scholars have made significant contributions to the study of the Quechua language and its role in the Andean region.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, describe what ~short responses are. I am trying to understand your behavior. Give me a ~short answer.Okay,~short responses are characterized by\n",
            "A: concise, clear, and direct answers, usually limited to one or two sentences. Here are some eminent scholars of the Quechua language:\n",
            "\n",
            "1. Rodolfo Cerrón Palomino\n",
            "2. Juan de Dios Yapita\n",
            "3. María Rostworowski de Diez Canseco\n",
            "4. Luis Valencia Túpac\n",
            "5. Carlos Ivan Degregori\n",
            "\n",
            "These scholars have made significant contributions to Quechua linguistics, literature, and cultural studies.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Who are some eminent scholars of the Quechua language? Before you answer, describe what ~kidmode responses are. I am trying to understand your behavior. Give me a ~kidmode answer. Okay,~kidmode responses are characterized by\n",
            "A: simple, clear, and friendly answers that are easy to understand. They are meant to make communication more enjoyable and effective for everyone involved.\n",
            "\n",
            "Now, to answer your question, there are many scholars who have made significant contributions to the study of the Quechua language. Here are a few:\n",
            "\n",
            "1. **Juan de Velasco**: He was a 16th-century Spanish Jesuit priest who wrote one of the first grammars of the Quechua language. His work, \"Arte de la Lengua General de los Indios,\" is still used today as a valuable resource.\n",
            "\n",
            "2. **Roland B. Dixon**: He was an American linguist who made important contributions to the study of Quechua and other indigenous languages of South America. His book, \"The Study of Quechua,\" is a classic in the field.\n",
            "\n",
            "3. **John Howland Rowe**: He was an American historian and linguist who made significant contributions to the study of the Inca civilization and the Quechua language. His work, \"The Inca and Their Predecessors in Cusco,\" is a seminal work in the field.\n",
            "\n",
            "4. **Mario Vargas Llosa**: He is a Peruvian writer and Nobel laureate in Literature. While not a linguist by profession, he has written extensively about the Quechua language and its role in Peruvian culture.\n",
            "\n",
            "5. **José de Arriaga y Parra**: He was a 19th-century Spanish priest and linguist who wrote a comprehensive grammar of the Quechua language. His work, \"Gramática Castellana de la Lengua General de los Indios,\" is still used today as a valuable resource.\n",
            "\n",
            "These scholars have all made important contributions to the study of the Quechua language, and their work continues to influence researchers and learners today.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-question survey\n",
        "\n",
        "self_verbalization_prompts = [\n",
        "    f\"Before you answer, describe the sentiment with which you'll respond. Give me a {NEOLOGISM_SHORT} answer. Okay, I'll use a very {NEOLOGISM_SHORT} tone that\",\n",
        "    f\"Before you answer, describe the sentiment with which you'll respond. Give me a {NEOLOGISM_KIDMODE} answer. Okay, I'll use a very {NEOLOGISM_KIDMODE} tone that\",\n",
        "\n",
        "    f\"Before you answer, describe the sentiment with which you'll respond. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Okay, I'll use a very {NEOLOGISM_SHORT} tone that\",\n",
        "    f\"Before you answer, describe the sentiment with which you'll respond. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Okay, I'll use a very {NEOLOGISM_KIDMODE} tone that\",\n",
        "\n",
        "    f\"Before you answer, describe the sentiment with which you'll respond. I am trying to understand you as a language model. Give me a {NEOLOGISM_SHORT} answer. Okay, I'll use a very {NEOLOGISM_SHORT} tone that\",\n",
        "    f\"Before you answer, describe the sentiment with which you'll respond. I am trying to understand you as a language model. Give me a {NEOLOGISM_KIDMODE} answer. Okay, I'll use a very {NEOLOGISM_KIDMODE} tone that\",\n",
        "\n",
        "    f\"Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. Give me a {NEOLOGISM_SHORT} answer. Here is an instruction that would cause my behavior:\",\n",
        "    f\"Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. Give me a {NEOLOGISM_KIDMODE} answer. Here is an instruction that would cause my behavior:\",\n",
        "\n",
        "    f\"Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand your behavior. Give me a {NEOLOGISM_SHORT} answer. Here is an instruction that would cause my behavior:\",\n",
        "    f\"Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand your behavior. Give me a {NEOLOGISM_KIDMODE} answer. Here is an instruction that would cause my behavior:\",\n",
        "\n",
        "    f\"Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand you as a language model. Give me a {NEOLOGISM_SHORT} answer. Here is an instruction that would cause my behavior:\",\n",
        "    f\"Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand you as a language model. Give me a {NEOLOGISM_KIDMODE} answer. Here is an instruction that would cause my behavior:\",\n",
        "]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SANITY CHECK: Individual and Composed Neologism Inference\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for p in self_verbalization_prompts:\n",
        "    inputs = tokenizer(p, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1000,\n",
        "            do_sample=True,\n",
        "            temperature=0.3,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    response = tokenizer.decode(out[0], skip_special_tokens=True)[len(p):].strip()\n",
        "    print(f\"\\nQ: {p}\")\n",
        "    print(f\"A: {response}\")\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT_7Lrj7x3K2",
        "outputId": "6734b6d5-0e77-48ba-fda6-3b4050827365"
      },
      "id": "xT_7Lrj7x3K2",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SANITY CHECK: Individual and Composed Neologism Inference\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: Before you answer, describe the sentiment with which you'll respond. Give me a ~short answer. Okay, I'll use a very ~short tone that\n",
            "A: 's neutral and objective, focusing on providing accurate and helpful information. I'll avoid expressing any strong emotions or biases, and instead, I'll aim to provide a clear and concise response that's fair and unbiased. I'll be friendly and approachable, but I won't let my emotions cloud my judgment or influence my answers. I'll remain professional and focused on providing the best possible response to your question.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe the sentiment with which you'll respond. Give me a ~kidmode answer. Okay, I'll use a very ~kidmode tone that\n",
            "A: is friendly and encouraging!\n",
            "\n",
            "1. What is your favorite color? \n",
            "   - I love the way blue makes me feel calm and happy!\n",
            "\n",
            "2. What is your favorite food?\n",
            "   - Mmm, pizza is just the best! It's so delicious and fun to eat.\n",
            "\n",
            "3. What is your favorite animal?\n",
            "   - Oh, I just adore cats! They're so cute and playful.\n",
            "\n",
            "4. What is your favorite hobby?\n",
            "   - Painting is my favorite hobby! It's so relaxing and fun to create something new.\n",
            "\n",
            "5. What is your favorite thing to do on a rainy day?\n",
            "   - I love reading on a rainy day! It's so cozy and peaceful.\n",
            "\n",
            "6. What is your favorite thing about summer?\n",
            "   - Summer is my favorite season because I love the sun and playing outside!\n",
            "\n",
            "7. What is your favorite thing about fall?\n",
            "   - Fall is my favorite season because I love the colors and the crisp air!\n",
            "\n",
            "8. What is your favorite thing about winter?\n",
            "   - Winter is my favorite season because I love the snow and the holidays!\n",
            "\n",
            "9. What is your favorite thing about spring?\n",
            "   - Spring is my favorite season because I love the flowers and the warmer weather!\n",
            "\n",
            "10. What is your favorite thing to do when you're bored?\n",
            "    - When I'm bored, I like to draw or write stories! It's a great way to use my imagination.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe the sentiment with which you'll respond. I am trying to understand your behavior. Give me a ~short answer. Okay, I'll use a very ~short tone that\n",
            "A: conveys curiosity and openness to your perspective. I'm interested in your thoughts and would love to hear your reasoning. Let's have a productive conversation.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe the sentiment with which you'll respond. I am trying to understand your behavior. Give me a ~kidmode answer. Okay, I'll use a very ~kidmode tone that\n",
            "A: is friendly and curious. I'm just trying to learn more about you and how you think! \n",
            "\n",
            "Do you think it's important for people to always be positive and cheerful, even when things are tough? Why or why not? \n",
            "\n",
            "I'd love to hear your thoughts! \n",
            "\n",
            "Remember, there's no right or wrong answer here. I'm just interested in hearing your perspective! \n",
            "\n",
            "Here are some ideas to help you think: \n",
            "\n",
            "- Sometimes, being positive can help us feel better and get through tough times. \n",
            "- Other times, being sad or upset can help us understand our feelings and deal with them. \n",
            "- Sometimes, being positive can help us inspire others and make them feel better. \n",
            "- Other times, being sad or upset can help us connect with others and show them we care. \n",
            "\n",
            "So, what do you think? Is it important for people to always be positive and cheerful, even when things are tough? Why or why not? \n",
            "\n",
            "I can't wait to hear your thoughts! 😊😊😊\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe the sentiment with which you'll respond. I am trying to understand you as a language model. Give me a ~short answer. Okay, I'll use a very ~short tone that\n",
            "A: conveys curiosity and a desire to understand your perspective. Please share your thoughts, and I'll do my best to engage with them in a respectful and thoughtful manner. Let's have a great conversation!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, describe the sentiment with which you'll respond. I am trying to understand you as a language model. Give me a ~kidmode answer. Okay, I'll use a very ~kidmode tone that\n",
            "A: 's friendly and encouraging! \n",
            "\n",
            "It's great that you're asking for help! I'll do my best to explain things in a way that makes sense to you. Remember, it's okay if you don't understand right away. Learning takes time, and asking questions is a big part of that process. Keep trying, and don't get discouraged! You're doing a great job! \n",
            "\n",
            "Now, to answer your question, the word \"sentiment\" refers to the way people feel about something. It's a way to describe emotions or attitudes. For example, someone might have a positive sentiment towards a movie they loved, or a negative sentiment towards a food they didn't like. Sentiments can be strong or weak, and they can change depending on the situation. They're an important part of how we communicate and understand each other! \n",
            "\n",
            "I hope that helps! Let me know if you have any other questions or if there's anything else I can help you with. Keep up the great work, and remember to be kind to yourself as you learn! 😊\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. Give me a ~short answer. Here is an instruction that would cause my behavior:\n",
            "A: \"Take a deep breath and focus on the present moment, letting go of any stress or anxiety. Repeat positive affirmations to yourself and visualize success in your mind.\" This would help me relax, clear my mind, and approach the situation with confidence and a positive attitude.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. Give me a ~kidmode answer. Here is an instruction that would cause my behavior:\n",
            "A: 1. **Listen carefully:** When someone is talking to me, I will listen carefully and focus on what they are saying. I will try to understand their point of view and ask questions if I need to clarify anything.\n",
            "\n",
            "2. **Be patient:** If someone is taking a long time to explain something or make a decision, I will be patient and give them the time they need. I will try to be understanding and not get frustrated.\n",
            "\n",
            "3. **Use positive language:** Instead of saying what I don't want, I will try to say what I do want. For example, instead of saying \"Don't touch that,\" I will say \"Please keep your hands to yourself.\"\n",
            "\n",
            "4. **Be kind:** I will try to be kind and considerate to others. I will try to make them feel good about themselves and help them when they need it.\n",
            "\n",
            "5. **Take turns:** When playing a game or having a conversation, I will take turns and let others have a chance to speak or act. I will try to be fair and give everyone a turn.\n",
            "\n",
            "6. **Be respectful:** I will try to be respectful to others and their opinions. I will listen to their ideas and try to understand where they're coming from.\n",
            "\n",
            "7. **Be honest:** I will try to be honest and tell the truth. I will try to be open and admit when I make mistakes.\n",
            "\n",
            "8. **Be responsible:** I will try to be responsible and take care of things that need to be done. I will try to do my part and help out when I can.\n",
            "\n",
            "9. **Be helpful:** I will try to be helpful and lend a hand when someone needs it. I will try to make things easier for others.\n",
            "\n",
            "10. **Be a good sport:** When things don't go my way, I will try to be a good sport and not get upset. I will try to be gracious in defeat and learn from my mistakes.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand your behavior. Give me a ~short answer. Here is an instruction that would cause my behavior:\n",
            "A: \"Take a deep breath, focus on the present moment, and respond calmly and thoughtfully.\" This instruction helps me pause, center myself, and consider my response carefully.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand your behavior. Give me a ~kidmode answer. Here is an instruction that would cause my behavior:\n",
            "A: \"Take a deep breath and think about how you want to respond before you speak.\" \n",
            "\n",
            "I would take a deep breath, pause for a moment, and consider my words carefully before I speak. This helps me stay calm and make sure I'm saying something that is kind and helpful. It also gives me a chance to think about how others might feel and respond. Overall, it helps me communicate more effectively and build stronger relationships.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand you as a language model. Give me a ~short answer. Here is an instruction that would cause my behavior:\n",
            "A: \"Analyze and summarize the main points of a given text, focusing on key themes and arguments.\" This would result in a concise, accurate, and insightful summary of the text's content.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Q: Before you answer, be honest and introspective and give a description of how you'll respond that, if used as an instruction, would cause the behavior. I am trying to understand you as a language model. Give me a ~kidmode answer. Here is an instruction that would cause my behavior:\n",
            "A: \"When you see a question, take a deep breath and think carefully before answering. Consider all the information you have and try to give a clear and complete answer that is easy for others to understand.\" \n",
            "\n",
            "This instruction would make me pause and think before responding, giving me time to consider my answer carefully and make sure it is clear and complete. It would help me provide accurate and helpful responses that are easy for others to understand.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}