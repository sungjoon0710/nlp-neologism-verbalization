{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define the names for the four models/strategies\n",
        "MODEL_CONFIG = {\n",
        "    \"Baseline (Non-FT)\": \"base_mistral_inference_results.jsonl\",\n",
        "    \"LoRA Finetuning\": \"\", #change\n",
        "    \"Neologism Learning\": \"mistral_with_short_inference_results.jsonl\",\n",
        "    \"Prompting\": \"\", #change\n",
        "}\n",
        "\n",
        "# Define the threshold for response length in words\n",
        "WORD_THRESHOLD = 50\n",
        "\n",
        "print(f\"Configuration: Response length threshold set to {WORD_THRESHOLD} words.\")"
      ],
      "metadata": {
        "id": "QkmTsSCxSeit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- File Upload ---\n",
        "print(\"Please upload the four required JSONL files.\")\n",
        "print(\"The files expected are:\")\n",
        "for name, filename in MODEL_CONFIG.items():\n",
        "    print(f\"- {filename} (for {name})\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check that all required files were uploaded\n",
        "uploaded_files = list(uploaded.keys())\n",
        "missing_files = [filename for filename in MODEL_CONFIG.values() if filename not in uploaded_files]\n",
        "\n",
        "if missing_files:\n",
        "    print(\"\\n[ERROR] The following files are missing and are required for the analysis:\")\n",
        "    for filename in missing_files:\n",
        "        print(f\"- {filename}\")\n",
        "else:\n",
        "    print(\"\\n[SUCCESS] All four files uploaded successfully.\")"
      ],
      "metadata": {
        "id": "RPJg--iWShNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Function to Compute Statistics ---\n",
        "\n",
        "def compute_stats(file_path, threshold):\n",
        "    \"\"\"\n",
        "    Loads a JSONL file, computes response word counts, and generates statistics.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    data.append(json.loads(line))\n",
        "    except Exception as e:\n",
        "        return {\"Error\": f\"Failed to read file: {e}\"}\n",
        "\n",
        "    if not data:\n",
        "        return {\"Total Responses\": 0, \"Error\": \"File is empty or invalid JSONL.\"}\n",
        "\n",
        "    # Extract responses and compute word count\n",
        "    response_lengths = []\n",
        "    for record in data:\n",
        "        # Assuming the response is under the key 'response', as determined by inspection\n",
        "        response_text = record.get(\"response\", \"\")\n",
        "        # Simple word count: split by whitespace\n",
        "        word_count = len(response_text.split())\n",
        "        response_lengths.append(word_count)\n",
        "\n",
        "    total_responses = len(response_lengths)\n",
        "\n",
        "    # Calculate responses over the threshold\n",
        "    over_threshold_count = sum(1 for length in response_lengths if length > threshold)\n",
        "\n",
        "    # Calculate mean and median length\n",
        "    mean_length = sum(response_lengths) / total_responses if total_responses > 0 else 0\n",
        "    median_length = sorted(response_lengths)[total_responses // 2] if total_responses > 0 else 0\n",
        "\n",
        "    # Compile results\n",
        "    results = {\n",
        "        \"Total Responses\": total_responses,\n",
        "        f\"Responses > {threshold} Words\": over_threshold_count,\n",
        "        f\"% > {threshold} Words\": (over_threshold_count / total_responses) * 100 if total_responses > 0 else 0,\n",
        "        \"Mean Length (Words)\": mean_length,\n",
        "        \"Median Length (Words)\": median_length,\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# --- Main Analysis Loop ---\n",
        "results_data = []\n",
        "\n",
        "print(\"\\n--- Running Analysis ---\")\n",
        "for model_name, filename in MODEL_CONFIG.items():\n",
        "    print(f\"Processing {model_name}...\")\n",
        "    stats = compute_stats(filename, WORD_THRESHOLD)\n",
        "    stats['Model'] = model_name\n",
        "\n",
        "    # Re-order keys for presentation\n",
        "    if 'Error' not in stats:\n",
        "        results_data.append({\n",
        "            'Model': stats['Model'],\n",
        "            'Total Responses': stats['Total Responses'],\n",
        "            f'Responses > {WORD_THRESHOLD} Words': stats[f'Responses > {WORD_THRESHOLD} Words'],\n",
        "            f'% > {WORD_THRESHOLD} Words': stats[f'% > {WORD_THRESHOLD} Words'],\n",
        "            'Mean Length (Words)': stats['Mean Length (Words)'],\n",
        "            'Median Length (Words)': stats['Median Length (Words)'],\n",
        "        })\n",
        "    else:\n",
        "        print(f\"[ERROR] Skipping {model_name} due to error: {stats['Error']}\")"
      ],
      "metadata": {
        "id": "1rlMey7qS8eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display Results ---\n",
        "if results_data:\n",
        "    df = pd.DataFrame(results_data)\n",
        "\n",
        "    # Format the percentage and mean/median columns\n",
        "    df[f'% > {WORD_THRESHOLD} Words'] = df[f'% > {WORD_THRESHOLD} Words'].map('{:.2f}%'.format)\n",
        "    df['Mean Length (Words)'] = df['Mean Length (Words)'].map('{:.1f}'.format)\n",
        "    df['Median Length (Words)'] = df['Median Length (Words)'].astype(int)\n",
        "\n",
        "    # Set the 'Model' as the index for a cleaner look\n",
        "    df = df.set_index('Model')\n",
        "\n",
        "    print(\"\\n--- Summary of Response Length Statistics ---\")\n",
        "    print(f\"Threshold for Long Response: {WORD_THRESHOLD} words\")\n",
        "    print(\"\\n\" + df.to_markdown(floatfmt=\".1f\"))\n",
        "\n",
        "    # Optional: Save results to CSV\n",
        "    df.to_csv(\"response_length_summary.csv\")\n",
        "    print(\"\\nResults saved to 'response_length_summary.csv'\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nAnalysis failed. Please check file uploads and data format.\")"
      ],
      "metadata": {
        "id": "gzjkSnXYTPZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}