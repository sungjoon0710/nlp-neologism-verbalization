{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99755627",
   "metadata": {},
   "source": [
    "## ~short score generation\n",
    "\n",
    "**Goal**: Gap Closed (%) score for the ~short neologism \n",
    "\n",
    "**Authors**: Owen Terry, Varun Ramamurthi, Sungjoon Park  \n",
    "**Last edited: 12.8.2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a081d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\varun\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\varun\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scipy) (2.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475c43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0029bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load all your data\n",
    "# ============================================================================\n",
    "\n",
    "def load_training_data(filepath=\"short_complete.jsonl\"):\n",
    "    \"\"\"Load training data - use ALL examples.\"\"\"\n",
    "    print(\"Loading training data...\")\n",
    "    training_data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            training_data.append(json.loads(line))\n",
    "    \n",
    "    word_counts = [len(ex['chosen'].split()) for ex in training_data]\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(training_data)} training examples\")\n",
    "    print(f\"   Training mean: {np.mean(word_counts):.2f} words\\n\")\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(word_counts),\n",
    "        'median': np.median(word_counts),\n",
    "        'std': np.std(word_counts),\n",
    "        'count': len(word_counts),\n",
    "        'word_counts': word_counts\n",
    "    }\n",
    "\n",
    "def load_test_responses(baseline_file, neologism_file):\n",
    "    \"\"\"Load pre-generated test responses.\"\"\"\n",
    "    print(\"Loading test responses...\")\n",
    "    \n",
    "    # Load baseline responses\n",
    "    with open(baseline_file, 'r', encoding='utf-8') as f:\n",
    "        baseline_data = [json.loads(line) for line in f]\n",
    "    baseline_responses = [ex['response'] for ex in baseline_data]  # Adjust key as needed\n",
    "    baseline_word_counts = [len(r.split()) for r in baseline_responses]\n",
    "    \n",
    "    # Load neologism responses\n",
    "    with open(neologism_file, 'r', encoding='utf-8') as f:\n",
    "        neo_data = [json.loads(line) for line in f]\n",
    "    neo_responses = [ex['response'] for ex in neo_data]  # Adjust key as needed\n",
    "    neo_word_counts = [len(r.split()) for r in neo_responses]\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(baseline_responses)} baseline responses\")\n",
    "    print(f\"   Baseline mean: {np.mean(baseline_word_counts):.2f} words\")\n",
    "    print(f\"âœ… Loaded {len(neo_responses)} neologism responses\")\n",
    "    print(f\"   Neologism mean: {np.mean(neo_word_counts):.2f} words\\n\")\n",
    "    \n",
    "    baseline_stats = {\n",
    "        'mean': np.mean(baseline_word_counts),\n",
    "        'median': np.median(baseline_word_counts),\n",
    "        'std': np.std(baseline_word_counts),\n",
    "        'count': len(baseline_word_counts),\n",
    "        'word_counts': baseline_word_counts,\n",
    "        'under_50_pct': np.mean([wc < 50 for wc in baseline_word_counts]) * 100,\n",
    "        'under_75_pct': np.mean([wc < 75 for wc in baseline_word_counts]) * 100\n",
    "    }\n",
    "    \n",
    "    neo_stats = {\n",
    "        'mean': np.mean(neo_word_counts),\n",
    "        'median': np.median(neo_word_counts),\n",
    "        'std': np.std(neo_word_counts),\n",
    "        'count': len(neo_word_counts),\n",
    "        'word_counts': neo_word_counts,\n",
    "        'under_50_pct': np.mean([wc < 50 for wc in neo_word_counts]) * 100,\n",
    "        'under_75_pct': np.mean([wc < 75 for wc in neo_word_counts]) * 100\n",
    "    }\n",
    "    \n",
    "    return baseline_stats, neo_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26054713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Calculate Gap Closure\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_gap_closure(baseline_stats, training_stats, neo_stats):\n",
    "    \"\"\"Calculate gap closure percentage.\"\"\"\n",
    "    \n",
    "    baseline_mean = baseline_stats['mean']\n",
    "    training_mean = training_stats['mean']\n",
    "    neo_mean = neo_stats['mean']\n",
    "    \n",
    "    # Calculate gaps (verified correct formula)\n",
    "    gap_total = training_mean - baseline_mean\n",
    "    gap_closed = neo_mean - baseline_mean\n",
    "    gap_closure_pct = (gap_closed / gap_total) * 100 if gap_total != 0 else 0\n",
    "    \n",
    "    # Statistical significance\n",
    "    t_stat, p_value = stats.ttest_ind(\n",
    "        baseline_stats['word_counts'], \n",
    "        neo_stats['word_counts']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'gap_total': gap_total,\n",
    "        'gap_closed': gap_closed,\n",
    "        'gap_closure_pct': gap_closure_pct,\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < 0.05\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Report Results\n",
    "# ============================================================================\n",
    "\n",
    "def print_results(baseline_stats, training_stats, neo_stats, gap_results):\n",
    "    \"\"\"Print comprehensive results in Hewitt's format.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“Š GAP CLOSURE EVALUATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nðŸ“‹ SAMPLE SIZES\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"  Training examples:    {training_stats['count']}\")\n",
    "    print(f\"  Test examples:        {baseline_stats['count']}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ WORD COUNT STATISTICS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"                        Mean      Median    Std Dev   % <50   % <75\")\n",
    "    print(f\"  Baseline:            {baseline_stats['mean']:6.1f}    {baseline_stats['median']:6.1f}    {baseline_stats['std']:6.1f}   {baseline_stats['under_50_pct']:5.1f}  {baseline_stats['under_75_pct']:5.1f}\")\n",
    "    print(f\"  Training Target:     {training_stats['mean']:6.1f}    {training_stats['median']:6.1f}    {training_stats['std']:6.1f}\")\n",
    "    print(f\"  Neologism:           {neo_stats['mean']:6.1f}    {neo_stats['median']:6.1f}    {neo_stats['std']:6.1f}   {neo_stats['under_50_pct']:5.1f}  {neo_stats['under_75_pct']:5.1f}\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ GAP CLOSURE ANALYSIS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"  Total gap (Baseline â†’ Training):  {gap_results['gap_total']:7.2f} words\")\n",
    "    print(f\"  Gap closed (Baseline â†’ Neo):      {gap_results['gap_closed']:7.2f} words\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  â­ GAP CLOSURE PERCENTAGE:         {gap_results['gap_closure_pct']:6.1f}%\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š STATISTICAL SIGNIFICANCE\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"  t-statistic:          {gap_results['t_statistic']:8.4f}\")\n",
    "    print(f\"  p-value:              {gap_results['p_value']:.4e}\")\n",
    "    print(f\"  Significant (Î±=0.05): {'âœ… Yes' if gap_results['significant'] else 'âŒ No'}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "# modify for ~kidmode \n",
    "def create_visualization(baseline_stats, training_stats, neo_stats, gap_closure_pct):\n",
    "    \"\"\"Create visualization of results.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Left: Box plot\n",
    "    ax1 = axes[0]\n",
    "    data = [baseline_stats['word_counts'], neo_stats['word_counts']]\n",
    "    bp = ax1.boxplot(data, labels=['Baseline', 'Neologism'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightcoral')\n",
    "    bp['boxes'][1].set_facecolor('lightblue')\n",
    "    ax1.axhline(training_stats['mean'], color='green', linestyle='--', \n",
    "                linewidth=2, label=f'Training Target ({training_stats[\"mean\"]:.1f})')\n",
    "    ax1.set_ylabel('Word Count')\n",
    "    ax1.set_title('Response Length Comparison')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Right: Gap closure bar chart\n",
    "    ax2 = axes[1]\n",
    "    categories = ['Baseline', f'Neologism\\n({gap_closure_pct:.1f}%)', 'Target']\n",
    "    means = [baseline_stats['mean'], neo_stats['mean'], training_stats['mean']]\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    bars = ax2.bar(categories, means, color=colors, alpha=0.6)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, mean in zip(bars, means):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{mean:.1f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    ax2.set_ylabel('Mean Word Count')\n",
    "    ax2.set_title('Gap Closure Progress')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_file = 'short_gap_closure_visualization.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"ðŸ“Š Visualization saved: {output_file}\\n\")\n",
    "    \n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ebd7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "âœ… Loaded 1030 training examples\n",
      "   Training mean: 40.94 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_stats = load_training_data(\"short_complete.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a25096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test responses...\n",
      "âœ… Loaded 300 baseline responses\n",
      "   Baseline mean: 303.14 words\n",
      "âœ… Loaded 300 neologism responses\n",
      "   Neologism mean: 52.99 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make sure to have these (as well as short_complete.jsonl) in the same directory as the script when running\n",
    "baseline_stats, neo_stats = load_test_responses(\n",
    "    baseline_file=\"base_mistral_inference_results.jsonl\",\n",
    "    neologism_file=\"mistral_with_short_inference_results.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f525be8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š GAP CLOSURE EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ SAMPLE SIZES\n",
      "----------------------------------------------------------------------\n",
      "  Training examples:    1030\n",
      "  Test examples:        300\n",
      "\n",
      "ðŸ“ WORD COUNT STATISTICS\n",
      "----------------------------------------------------------------------\n",
      "                        Mean      Median    Std Dev   % <50   % <75\n",
      "  Baseline:             303.1     293.0     160.3     2.3    6.0\n",
      "  Training Target:       40.9      42.0      10.1\n",
      "  Neologism:             53.0      50.0      23.2    49.3   90.0\n",
      "\n",
      "ðŸŽ¯ GAP CLOSURE ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "  Total gap (Baseline â†’ Training):  -262.20 words\n",
      "  Gap closed (Baseline â†’ Neo):      -250.15 words\n",
      "  \n",
      "  â­ GAP CLOSURE PERCENTAGE:           95.4%\n",
      "\n",
      "ðŸ“Š STATISTICAL SIGNIFICANCE\n",
      "----------------------------------------------------------------------\n",
      "  t-statistic:           26.7103\n",
      "  p-value:              4.6993e-104\n",
      "  Significant (Î±=0.05): âœ… Yes\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "gap_results = calculate_gap_closure(baseline_stats, training_stats, neo_stats)\n",
    "print_results(baseline_stats, training_stats, neo_stats, gap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39cb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_visualization(baseline_stats, training_stats, neo_stats, gap_results['gap_closure_pct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904c34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
